{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c5a0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming 3 topics, 6 speakers, speakers have 10,9,8,7,6,5 speeches for a total of 45 speeches. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f6caa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "#ec - extreme conservative, mc - moderate conservative, ml - moderate liberal, el - extreme liberal\n",
    "vocab = ['unborn', #ec\n",
    "         'unborn_child', #ec\n",
    "         'baby', #ec\n",
    "         'babies', #ec\n",
    "         'murder', #ec\n",
    "         'life', #mc\n",
    "         'heartbeat', #mc\n",
    "        'weeks', #mc\n",
    "         'stem', #mc\n",
    "         'late_abortion', #mc\n",
    "        'women', #ml\n",
    "         'rare', #ml\n",
    "         'legal', #ml\n",
    "         'healthcare', #ml\n",
    "         'choice', #ml\n",
    "         'rights', #el\n",
    "         'bodily_autonomy', #el\n",
    "         'birth_control', #el \n",
    "         'contraception', #el\n",
    "         'access', #el\n",
    "         'illegal', #ec\n",
    "        'illegal_immigrants',  #ec\n",
    "         'enforce', #ec\n",
    "         'amnesty', #ec\n",
    "         'wall', #ec\n",
    "         'law', #mc\n",
    "         'immigration', #mc\n",
    "         'secure', #mc\n",
    "         'border', #mc\n",
    "         'homeland_security', #mc\n",
    "        'legal_immigration', #ml\n",
    "         'immigrant_rights', #ml\n",
    "         'immigrant', #ml \n",
    "         'refugees', #ml\n",
    "         'america', #ml\n",
    "         'dreamer', #el\n",
    "         'daca', #el\n",
    "         'comprehensive_immigration_reform', #el\n",
    "         'deportation', #el\n",
    "         'broken_system', #el\n",
    "         'hoax', #ec \n",
    "         'china', #ec\n",
    "         'coal', #ec\n",
    "         'production', #ec\n",
    "         'govt_overreach', #ec\n",
    "         'energy', #mc \n",
    "         'mine_workers', #mc \n",
    "         'jobs', #mc\n",
    "         'economy', #mc\n",
    "         'oil', #mc\n",
    "        'climate_change', #ml\n",
    "         'carbon_tax', #ml\n",
    "         'clean_energy', #ml\n",
    "         'pollution', #ml\n",
    "         'global_warming', #ml\n",
    "        'solar', #el\n",
    "         'wind', #el\n",
    "         'renewable', #el\n",
    "         'energy_efficiency', #el\n",
    "         'crisis'] #el\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58d0bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_abortion_inds = [0, 1, 2, 3, 4]\n",
    "mc_abortion_inds = [5, 6, 7, 8, 9]\n",
    "ml_abortion_inds = [10, 11, 12, 13, 14]\n",
    "el_abortion_inds = [15, 16, 17, 18, 19]\n",
    "\n",
    "ec_immigration_inds = [20, 21, 22, 23, 24]\n",
    "mc_immigration_inds = [25, 26, 27, 28, 29]\n",
    "ml_immigration_inds = [30, 31, 32, 33, 34]\n",
    "el_immigration_inds = [35, 36, 37, 38, 39]\n",
    "\n",
    "ec_energy_inds = [40, 41, 42, 43, 44]\n",
    "mc_energy_inds = [45, 46, 47, 48, 49]\n",
    "ml_energy_inds = [50, 51, 52, 53, 54]\n",
    "el_energy_inds = [55, 56, 57, 58, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2b7ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3953ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "speaker1 = 'Mark (R)' #Conservative - Extremely cons. on abortion, moderate on other two, 4 speeches on abortion and 3 on energy, 3 on immigration\n",
    "\n",
    "l = []\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f12d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "speaker2 = 'Lauren (R)' #Conservative - extreme cons. on immigration, moderate on other two, 3 speeches on abortion and 1 on energy, 4 on immigration\n",
    "\n",
    "l = []\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca177876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "speaker3 = 'John (R)' #Conservative - moderate cons. on immigration, extreme on other two, 1 speech on immigration and 3 on energy, 1 on abortion\n",
    "\n",
    "l = []\n",
    "for i in mc_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ec_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ec_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in mc_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(ml_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "262d1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "speaker4 = 'Mona (D)' #Liberal - Extremely lib. on abortion and energy, moderate on immigration, 3 speeches on abortion, 3 on energy, 3 on immigration\n",
    "\n",
    "l = []\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ddf86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "speaker5 = 'Justicia (D)' #Liberal - Extremely lib. on abortion and immigration, moderate on energy, 3 speeches on abortion, 1 on energy, 3 on immigration\n",
    "\n",
    "l = []\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5248d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "speaker6 = 'Alex (D)' #Liberal - moderate on all issues, 2 speeches on abortion, 2 on energy, 2 on immigration\n",
    "\n",
    "l = []\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_immigration_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_immigration_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_immigration_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_energy_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_energy_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_energy_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "l = []\n",
    "for i in ml_abortion_inds:\n",
    "    l = l + [vocab[i]]*(8 + random.choice([-2, -1, 0, 1, 2]))\n",
    "for i in el_abortion_inds:\n",
    "    l = l + [vocab[i]]*3\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "l = l + [vocab[random.choice(mc_abortion_inds)]]*2\n",
    "speeches.append(l)\n",
    "\n",
    "print(len(speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a57aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "speakers = [speaker1]*10 + [speaker2]*8 + [speaker3]*5 + [speaker4]*9 + [speaker5]*7 + [speaker6]*6\n",
    "print(len(speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3301fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "speaker_to_speaker_id = dict(\n",
    "    [(y, x) for x, y in enumerate(sorted(set(speakers)))])\n",
    "author_indices = np.array(\n",
    "    [speaker_to_speaker_id[s] for s in speakers])\n",
    "print(len(author_indices))\n",
    "author_map = np.array(list(speaker_to_speaker_id.keys()))\n",
    "print(len(author_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "579bd572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 60)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "counts = count_vectorizer.fit_transform(list(map(lambda x:' '.join(x), speeches)))\n",
    "vocabulary = np.array(\n",
    "    [k for (k, v) in sorted(count_vectorizer.vocabulary_.items(), \n",
    "                            key=lambda kv: kv[1])])\n",
    "print(counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "303c86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data.\n",
    "\n",
    "# `counts.npz` is a [num_documents, num_words] sparse matrix containing the\n",
    "# word counts for each document.\n",
    "sparse.save_npz(\"clean/counts.npz\",\n",
    "                counts.astype(np.float32))\n",
    "\n",
    "# `author_indices.npy` is a [num_documents] vector where each entry is an\n",
    "# integer indicating the author of the corresponding document.\n",
    "np.save(\"clean/author_indices.npy\", author_indices)\n",
    "\n",
    "# `vocabulary.txt` is a [num_words] vector where each entry is a string\n",
    "# denoting the corresponding word in the vocabulary.\n",
    "np.savetxt(\"clean/vocabulary.txt\", vocabulary, fmt=\"%s\")\n",
    "\n",
    "# `author_map.txt` is a [num_authors] vector of strings providing the bioguide ID of\n",
    "# each author in the corpus.\n",
    "np.savetxt(\"clean/author_map.txt\", author_map, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f5845c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 3 0 2]\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 3 0 2]\n",
      " ...\n",
      " [0 0 0 ... 0 3 0]\n",
      " [3 0 0 ... 0 0 8]\n",
      " [3 0 0 ... 2 0 9]]\n"
     ]
    }
   ],
   "source": [
    "print(counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e17919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 199"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
